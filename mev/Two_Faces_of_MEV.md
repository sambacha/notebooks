---
created: 2022-09-16T18:39:55 (UTC -07:00)
tags: []
source: https://notes.ethereum.org/NMZOENlART-yGAZWH8Y0Rg
author: 
---

# Two faces of MEV: user exploitation minimization and value capture maximization 

In the following, I am going to argue that even if strategies like fair ordering or content layer consensus approaches are shown to be efficiently implementable and very effective at minimizing MEV, blindly deploying them is  not necessarily the best possible MEV-conscious design, for reasons beyond the &#34;MEV from arbitrage between fairness notions &#34;posited by Phil Daian in his blog post [MEVâ€¦ wat do?](https://pdaian.com/blog/mev-wat-do). 

As Dan Robinson suggested in &#34;The Meta MEV Discussions &#34;panel during [mev.wtf](https://hackmd.io/ivUzk3piQEG8ALzCGbxlag), such approaches have the undesirable side effect of inefficiently channeling resources. MEV is definitionally minimized because most of the value is not extractable by consensus actors such as block proposers, but a lot of value is still there and will just be assigned through different games. In particular, there is no way to minimize the value from blind frontrunning, which in mev.wtf has been repeatedly defined as frontrunning that does not depend on any particular transaction but just on previous state or off-chain information, as is the case for closing arbitrage opportunities opened in a previous block, for CEX arbitrage, for reacting to real-time market movements, for frontrunning token launches etc... The exact place these resources will go towards is not obvious, but minimization of response times and optimal positioning in the p2p network are some of the candidates. The latter is also potentially concerning from a security perspective, because MEV could subsidize the buildup and maintanance of very powerful actors in the p2p network, which pose a security threat given their ability to monitor and influence the global flow of information. [^1] 

All of these approaches also serve to protect regular users from frontrunning, and this is something that we should definitely achieve. On the other end, when it comes to blind frontrunning, such approaches do not protect users from the instances in which it is not victimless, as it is for example the case in permissionless token launches. In fact, blind frontrunning is not at all preventable when it comes to totally permissionless opportunities. For example, in a first-come-first-serve token launch without a buy limit (which would require some proof of unique humanity to be meaningfully implemented on chain, and thus permissions), the notions of fairness approximated by fair ordering produce outcomes which for normal participants are all but identical to PGAs or Flashbots auctions: losing to participants with more resources and/or sophistication.
In general, is there any reason to consider these alternative games fair? Is it important whether the fastest bot wins rather than the highest paying one? Given that the benefits generated for the collective by this competition are not particularly compelling, why should it be incentivized just to preserve some arbitrary notion of fairness which does not actually benefit normal users? One could argue that the fairest way to allocate the value extracted from opportunities that are not generated by any particular actor or protocol is to socialize it, to ETH holders or validators, or for public goods funding if there is a governance structure that enables it.


Is there actually a dichotomy between user harm minimization (ex. fair ordering) and protocol value capture maximization (ex. MEVA, EIP 1559)? I suggest that this is not the case, and both goals are in principle achievable at once, if we restrict ourselves to maximizing value capture from non-exploitative MEV.


An important observation is the following one. [^2]

```
MEV that isn &#39;t pMEV or convertible to pMEV through cooperation is exploitative
```

Note that this does not say that pMEV cannot be exploitative, which is clear since frontrunning can be exploitative and is a form of pMEV. Converting MEV into pMEV through cooperation here refers to the possibility of sharing MEV profits with transactions that the MEV opportunity depends on in order to obtain permission to include such transactions in a bundle which atomically extracts the MEV. This could for example be done with oracle updates which create liquidation opportunities. [^5] If sharing the profits is not possible in a way which is profitable for the issuer of the transaction which creates the opportunity, and thus cooperation cannot even in principle be attempted, we can only conclude that the MEV opportunity is exploitative, because no fraction of the profits can compensate the value taken away by the extraction. This is for example the case with a sandwich, since the MEV extracted by it is entirely taken from the exploited user, and thus it is not possible to for the user and the bot to share that value in a mutually beneficial way.


If we want to maximize value capture from MEV ethically, without harming users, we can therefore restrict ourselves to pMEV, and attempt to allow optimal conversion of all possible remaining MEV into this form. This does not mean that we should extract all pMEV, since some pMEV is also exploitative, but that focusing on pMEV only does not harm our goal of maximal value capture from non-exploitative MEV.


Given this knowledge, how can we decouple value capture maximization and user harm minimization in a way which lets us at least in principle target the optimum of both? My proposal is to split each block into two components, a priority area and a regular area, executed in this order. Since all non-exploitative MEV can be turned into pMEV, we can attempt to concentrate all such MEV into the priority area. Properly defined pMEV will naturally compete for inclusion in it, and we can attempt to facilitate conversion of any remaining non-exploitative MEV into pMEV. In particular, a transaction could be marked by its issuer as &#34;bundlable &#34;, meaning it can be inserted into a priority bundle, for inclusion in the priority area. If it is inserted, the issuer of the tx receives some payment from that of the priority bundle. Maybe the latter simply pays for gas, or the former is able to express what payment they require, which they could do based on some estimation of the MEV that the transaction creates. Such a transaction could also be normally inserted in the regular area if no priority bundle decides to include it, and in that case it behaves like every regular transaction, so that there &#39;s no downside to being marked this way for transactions which are not at risk of losing value to frontrunning.[^3] We can then attempt to maximize value capture from the transactions in the priority area, for example by auctioning off the right to build it, through a priority fee, through some consensus modifications which incentivize the burning or sharing of maximal profits etc... 

We can then apply harm minimization techniques to protect the transactions in the regular area from frontrunning, sandwitching and any other manner of exploitation. Since we have isolated which transactions we need to protect, this does not go against the goal of maximizing value capture. For example, if we decide that mempool privacy through threshold encryption is an efficiently implementable strategy, we can apply it to all transactions which wish to be protected (including priority transactions, which could be useful to mitigate the centralization risks stemming from searchers needing privacy), while still being able to distinguish priority transactions from regular ones before decryption. What &#39;s also interesting about this specific example is that threshold encryption by itself is primarily vulnerable to blind frontrunning, possibly through transaction spamming if the order is also randomized. Fair ordering attempts to solve this issue, which is why the two are planned to be composed in ChainLink &#39;s FSS. If we are not concerned about preventing &#34;unfair &#34;extraction through blind frontrunning, threshold encryption alone should work almost just as well, without requiring another consensus process for ordering [^4]


Another positive aspect of the division between priority area and regular area is that it clearly circumscribes a small set of transactions, and a corresponding small portion of the block, which can be used to maximize value capture, without involving the rest of the block and thus without endangering censorship resistance. For example, in the scheme from the [post](https://ethresear.ch/t/proposer-block-builder-separation-friendly-fee-market-designs/9725/41) about proposer/builders separation, a concern is that the builders market might be quite centralized, and a need for separate transactions added by the proposer might arise to ensure censorship resistance. A natural way to go about it could be to have builders be responsible for making the priority area of the block, and the proposer for making the regular area. Assuming we can mostly protect users from exploitative MEV extraction, there should be little difference in the profits of sophisticated and unsophisticated proposers, because there wouldn &#39;t be much MEV to be extracted in the regular area. [^6]






[^1]: Note to self: how does this relate to the security of fair ordering? Are aequitas security results ignoring the p2p layer and just equating nodes and validators? (or anyway nodes with nodes with a specific role in the system) 

[^2]: Strictly speaking we should start the observation by referring only to competitive MEV, which is MEV that can be competed over by different transactions. Fees are a non-example, as is &#34;subjective MEV &#34;, which is value that is only such for some participants. Non-competitive MEV can come from anywhere in the block without being exploitative, because the lack of competition makes it insensitive to order. The value capture from the order insensitive portion of fees is already somewhat handled by EIP 1559, and value capture from subjective MEV is impossible to guarantee, because it cannot be taken into account by a market of builders trying to maximize value. If this market was perfectly efficient, there would never be any reason for someone to bid the maximum &#34;commonly extractable &#34;value plus their own subjectively extractable value, because the former would suffice. 
While the reasoning concerns MEV coming from transaction inclusion and ordering, this notion also applies to censoring, which of course cannot be turned into pMEV. 


[^3]: Some transactions could be marked this way and just propagated through normal channels, others could be sent to trusted parties like it happens today with e.g. mistX, to ensure optimal returns for users

[^4]: Threshold encryption is also subject to metadata-based frontrunning, so maybe we do need a stronger protection. It is possible to circumvent this issue for the specific transactions which require it, without too much overhead, through exploitation of EIP 3074, maybe with some modifications. For example, a DEX &#39;s frontend could submit user transactions as authorized calls from their Invoker, so the sender address could be used to check the presence of sufficient funds to pay for the transaction before decryption, without revealing the real sender and their assets.
What about rollup transactions which are very easily identifiable from their gas limit? 

[^5]: This is not just a theoretical possibility. Some liquidations are already designed to work in a way which requires frontrunning to capture them (e.g. Compound open price feed). 

[^6]: Note to self: how does this work with different EEs? (even just rollups). </div>
 